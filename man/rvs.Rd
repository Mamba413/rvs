% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rvs.R
\name{rvs}
\alias{rvs}
\title{Robust variable selection with exponential squared loss}
\usage{
rvs(x, y, gamma = NULL, lambda = 1, weight = NULL, intercept = FALSE)
}
\arguments{
\item{x}{input matrix; each row is an observation vector.}

\item{y}{response variable.}

\item{gamma}{tuning parameter in the loss function.
The loss function defined as \deqn{1-exp(-t^2/\gamma)}}

\item{lambda}{regularization parameters in the penalty.
The penalty is defined as \deqn{\lambda\sum_{j=1}^p weight_{j}|\beta_j|.}}

\item{weight}{If \code{weight=NULL},
it is set to be \eqn{(log(n))/(n|\tilde{\beta}_j|),}
where \eqn{\tilde{\beta}} is an initial estimator.
If also \code{lambda=1}(by default),
the parameters meet a BIC-type criterion.}

\item{intercept}{should intercepts be fitted(TRUE) or set to zero(FALSE)}
}
\value{
A numerical vector \code{beta}, which is the estimated regression coefficients.
}
\description{
\code{rvs} carries out robust variable selection with exponential squared loss. 
A block coordinate gradient descent is implemented to minimize the loss function.
}
\details{
\code{rvs} solves the following optimization problem to obtain robust estimators of regression coefficients:
\deqn{argmin_{\beta} \sum_{i=1}^n(1-exp{-(y_i-x_i^T\beta)^2/\gamma_n})+n\sum_{i=1}^d p_{\lambda_{nj}(|\beta_j|)}.}
We use the adaptive LASSO penalty. Regularization parameters are chosen adaptively by default, while they can be supplied by the user.
Block coordinate gradient descent algorithm is used to efficiently solve the optimiztion problem.
}
\examples{
library(MASS)
N <- 100
p <- 8
rho <- 0.2
mu <- rep(0, p)
Sigma <- rho * outer(rep(1, p), rep(1, p)) + (1 - rho) * diag(p)
ind <- 1:p
beta <- (-1)^ind * exp(-2 * (ind - 1) / 20)
lambda_seq <- seq(0.05, 5, length.out = 100)
X <- mvrnorm(N, mu, Sigma)
Z <- rnorm(N, 0, 1)
k <- sqrt(var(X \%*\% beta) / (3 * var(Z)))
Y <- X \%*\% beta + drop(k) * Z
rvs(X, Y)
}
\references{
Xueqin Wang, Yunlu Jiang, Mian Huang & Heping Zhang (2013) Robust Variable Selection With Exponential Squared Loss, Journal of the American Statistical Association, 108:502, 632-643, DOI: 10.1080/01621459.2013.766613

Tseng, P., Yun, S. A coordinate gradient descent method for nonsmooth separable minimization. Math. Program. 117, 387-423 (2009). https://doi.org/10.1007/s10107-007-0170-0
}
\author{
Borui Tang, Jin Zhu, Xueqin Wang
}
